{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try (and fail) to do model comparison using Annealed Importance Sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "np.random.seed(33333)\n",
    "torch.manual_seed(33333)\n",
    "%matplotlib inline\n",
    "\n",
    "import analysis\n",
    "import razor_data\n",
    "import toy_data\n",
    "import plotting\n",
    "import gp\n",
    "importlib.reload(analysis);\n",
    "importlib.reload(razor_data);\n",
    "importlib.reload(toy_data);\n",
    "importlib.reload(plotting);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "box = 'SevenJet'\n",
    "btags = 2\n",
    "num_mr_bins = 50\n",
    "mr_max = 4000\n",
    "sms = 'T1tttt_1800_100'\n",
    "mu_true = 1.0\n",
    "mu_test = 1.0\n",
    "k_ell = 700\n",
    "k_alpha = 400\n",
    "num_runs = 25\n",
    "num_hmc_steps = 25\n",
    "num_beta = 1000\n",
    "iterations = 20\n",
    "verbose = True\n",
    "precomputed_pars = {\n",
    "    0:     (-3.7544545280775132, 2),\n",
    "    1e-10: (-4.0254054077081971, 3),\n",
    "    1e-5:  (-3.2527301493272569, 4),\n",
    "}\n",
    "result = analysis.bayes_opt_annealing(box, btags, num_mr_bins, mr_max, sms, mu_true, mu_test=mu_true,\n",
    "                k_ell=k_ell, k_alpha=k_alpha, \n",
    "                num_runs=num_runs, num_hmc_steps=num_hmc_steps, num_beta=num_beta, \n",
    "                iterations=iterations, verbose=verbose, precomputed_pars=precomputed_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteratively tuned the annealing schedule with the HMC parameters to get somewhat stable sampling from the posterior distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_w = 1830.0148997306824\n",
      "Last jump made: 25048 (0.9998187801154569)\n",
      "log_w = 1773.8858518600464\n",
      "Last jump made: 25049 (0.9998221990545706)\n",
      "log_w = 1695.7134890556335\n",
      "Last jump made: 25097 (0.9999863218816951)\n",
      "log_w = 1835.2184739112854\n",
      "Last jump made: 25052 (0.9998324559420597)\n",
      "log_w = 1799.5267882347107\n",
      "Last jump made: 24988 (0.9996136651621291)\n",
      "log_w = 1820.6234884262085\n",
      "Last jump made: 24957 (0.9995077055905424)\n",
      "log_w = 1823.7869954109192\n",
      "Last jump made: 24925 (0.9993983397493325)\n",
      "log_w = 1830.0412197113037\n",
      "Last jump made: 24696 (0.9986160396092096)\n",
      "log_w = 1820.5313396453857\n",
      "Last jump made: 25059 (0.9998563890887346)\n",
      "log_w = 1813.1622202396393\n",
      "Last jump made: 25020 (0.9997230545667612)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-118a683a878a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m G = analysis.fit_annealer(box, btags, num_mr_bins, mr_max, sms, mu_true, mu_test, k_ell, k_alpha, \n\u001b[1;32m     25\u001b[0m                          \u001b[0mnum_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_runs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hmc_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_hmc_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_beta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                          best_params=best_params, verbose=verbose)\n\u001b[0m",
      "\u001b[0;32m/nfshome/duanders/gpu-3-imperium/data/MLPhysics/razor_fits/gp/analysis.py\u001b[0m in \u001b[0;36mfit_annealer\u001b[0;34m(box, btags, num_mr_bins, mr_max, sms, mu_true, mu_test, k_ell, k_alpha, par_scheduler, last_beta, num_runs, num_hmc_steps, num_beta, verbose, best_params)\u001b[0m\n\u001b[1;32m    356\u001b[0m             num_true_signal=true_signal.sum())\n\u001b[1;32m    357\u001b[0m     G.sample(num_runs, num_hmc_steps, num_beta, \n\u001b[0;32m--> 358\u001b[0;31m              verbose=verbose, print_every=100, last_beta=last_beta)\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/duanders/gpu-3-imperium/data/MLPhysics/razor_fits/gp/gp/poisson_likelihood_gp.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, num_runs, num_hmc_samples, num_beta, verbose, abort_on_error, print_every, last_beta)\u001b[0m\n\u001b[1;32m    418\u001b[0m                 \u001b[0mnum_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpar_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhmc_par_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m                 abort_on_error=abort_on_error, last_beta=last_beta)\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;31m# we don't have to throw any samples away as warm-up with this algo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannealer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/duanders/gpu-3-imperium/data/MLPhysics/razor_fits/gp/gp/annealing.py\u001b[0m in \u001b[0;36mrun_annealing\u001b[0;34m(G, parameters, num_runs, num_hmc_samples, num_beta, epsilon, L_max, verbose, print_every, par_scheduler, abort_on_error, last_beta)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnlogp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mannealer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mannealer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/duanders/gpu-3-imperium/data/MLPhysics/razor_fits/gp/gp/annealing.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mthis_closure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hmc_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0minitial_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0minitial_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mfinal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/duanders/gpu-3-imperium/data/MLPhysics/razor_fits/gp/gp/hmc.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0;31m# Errors in the loss calculation are caused by overflows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/duanders/gpu-3-imperium/data/MLPhysics/razor_fits/gp/gp/annealing.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_beta\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_beta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mthis_closure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hmc_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0minitial_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/duanders/gpu-3-imperium/data/MLPhysics/razor_fits/gp/gp/annealing.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(beta)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mnlogp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_log_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mnlogp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnlogp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "box = 'SevenJet'\n",
    "btags = 2\n",
    "num_mr_bins = 50\n",
    "mr_max = 4000\n",
    "sms = 'T1tttt_1800_100'\n",
    "mu_true = 1.0\n",
    "mu_test = 1.0\n",
    "k_ell = 700\n",
    "k_alpha = 400\n",
    "num_runs = 100\n",
    "num_hmc_steps = 1\n",
    "num_beta = 1000\n",
    "verbose = True\n",
    "best_params = {\n",
    "    0:     (-3.0, 3),\n",
    "    1e-10: (-3.0, 3),\n",
    "    1e-5:  (-3.25, 4),\n",
    "    0.01:  (-3.0, 3),\n",
    "    0.05:  (-4.5, 3),\n",
    "    0.3:   (-5.0, 3),\n",
    "    0.95:  (-5.0, 3),\n",
    "    1:     (-5.5, 30),\n",
    "}\n",
    "G = analysis.fit_annealer(box, btags, num_mr_bins, mr_max, sms, mu_true, mu_test, k_ell, k_alpha, \n",
    "                         num_runs=num_runs, num_hmc_steps=num_hmc_steps, num_beta=num_beta,\n",
    "                         best_params=best_params, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The samples from the prior are usually annealed all the way to T=0 without \"falling off\" the distribution (which happens when the annealing proceeds too quickly).  But A) it's excruciatingly slow, and B) the importance weights span many orders of magnitude, which makes this impractical (the effective sample size is proportional to the variance of the importance weights)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
